{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code base 'is' built to parse and extract specific values from RC1 and NRW documents (ie: South African documents)\n",
    "# and the Japanese Export Certificate document. The Main technologies used are:\n",
    "# - Python (Primary Language of the code)\n",
    "# - Google cloud Vision (document scanner and computer vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, io\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "from google.cloud import translate_v2 as translate\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from enum import Enum\n",
    "from termcolor import colored\n",
    "import uuid\n",
    "from itertools import groupby\n",
    "import statistics\n",
    "# for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'Demz_vision_API_token.json' # google API credentials\n",
    "\n",
    "# Path to the rc1\n",
    "rc1_1 = 'rc1-1.jpg'\n",
    "rc1_2 = 'rc1-2.jpg'\n",
    "FOLDER_PATH = 'C:\\\\Users\\\\USER\\\\Desktop\\\\NEW_DEMZ\\\\OCR\\OCR_Works\\\\Google\\\\rc1\\\\images'\n",
    "\n",
    "# # Path to the rc1\n",
    "# nrw_1 = 'nrw-1.jpg'\n",
    "# nrw_2 = 'nrw-2.jpg'\n",
    "# nrw_3 = 'nrw-3.jpg'\n",
    "# FOLDER_PATH = 'C:\\\\Users\\\\USER\\\\Desktop\\\\NEW_DEMZ\\\\OCR\\OCR_Works\\\\Google\\\\nrw\\\\images'\n",
    "\n",
    "japan1 = 'japanese.jpg'\n",
    "# japan2 = 'jap_exp_cert_sample_1.jpg'\n",
    "# japan3 = 'jap_exp_cert_sample_2.png'\n",
    "# japan4 = 'jap_exp_cert_sample_3.jpg'\n",
    "# japan5 = 'jap_exp_cert_sample_1_auto_x1_colored_toned.jpg'\n",
    "FOLDER_PATH = 'C:\\\\Users\\\\USER\\\\Desktop\\\\NEW_DEMZ\\\\OCR\\\\OCR_Works\\\\Google\\\\japanese\\\\images'\n",
    "\n",
    "image = japan1 \n",
    "image = os.path.join(FOLDER_PATH, image) # full path to the image\n",
    "\n",
    "# google vision and translation APIs\n",
    "vision_client = vision.ImageAnnotatorClient()\n",
    "translate_client = translate.Client()\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jap_parser(image):\n",
    "    \"\"\"This functionality is to parse the Japanese document. Feel free to add updates\"\"\"\n",
    "    \n",
    "    # Open and Read contents on the documents\n",
    "    with io.open(image, 'rb') as image_file1:\n",
    "            content = image_file1.read()\n",
    "    content_image = vision.Image(content=content) # Reading the Image Content \n",
    "    rc1_response = vision_client.document_text_detection(\n",
    "        image=content_image,\n",
    "        image_context={\"language_hints\": 'ja'},  # Japanese\n",
    "    )\n",
    "    rc1_texts = rc1_response.text_annotations # Text Response\n",
    "\n",
    "    # face detection\n",
    "    response_face = client.face_detection(image=content_image)\n",
    "    faceAnnotations = response_face.face_annotations\n",
    "    \n",
    "    \n",
    "    # rearrange the Response using the bbox values\n",
    "    items = []\n",
    "    lines = {}\n",
    "\n",
    "    for text in rc1_response.text_annotations[1:]:\n",
    "        left_x_axis = text.bounding_poly.vertices[0].x # top left\n",
    "        left_y_axis = text.bounding_poly.vertices[0].y # top left\n",
    "        top_x_axis = text.bounding_poly.vertices[1].x # top\n",
    "        top_y_axis = text.bounding_poly.vertices[1].y # top\n",
    "        right_x_axis = text.bounding_poly.vertices[2].x # right\n",
    "        right_y_axis = text.bounding_poly.vertices[2].y # right\n",
    "        bottom_x_axis = text.bounding_poly.vertices[3].x # bottom\n",
    "        bottom_y_axis = text.bounding_poly.vertices[3].y # bottom\n",
    "        \n",
    "        # Arranging the bounding_polys\n",
    "        if left_y_axis not in lines:\n",
    "            lines[left_y_axis] = [(left_y_axis, bottom_y_axis), []]\n",
    "        for s_top_y_axis, s_item in lines.items():\n",
    "            if left_y_axis < s_item[0][1]:\n",
    "                face_vertices = (['({0},{1})'.format(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices])\n",
    "                                            #    Left            # Bottom    # Right        # vertices.      # Text       incase you still want to rearrange them in the future\n",
    "                lines[s_top_y_axis][1].append(([left_x_axis, bottom_y_axis, top_x_axis, (face_vertices)], text.description))\n",
    "                break\n",
    "    for _, item in lines.items():\n",
    "        if item[1]:\n",
    "            words = sorted(item[1], key=lambda t: t[0])\n",
    "            items.append((item[0], ' '.join([word for _, word in words]), words))\n",
    "            \n",
    "    def find_common_space(items):\n",
    "        \"\"\"Find common line spaces in the document\"\"\"\n",
    "        spaces = []\n",
    "        for i,k in enumerate(items):\n",
    "            try:\n",
    "                calculated_space = items[i][2][0][0][1] - items[i -1][2][0][0][1]\n",
    "                spaces.append(calculated_space)\n",
    "            except:\n",
    "                ...\n",
    "\n",
    "        common_space = abs(statistics.median(spaces))\n",
    "\n",
    "        return common_space\n",
    "\n",
    "    # Split the content based on horizontal space\n",
    "    new_content = []\n",
    "    most_common_space = find_common_space(items)\n",
    "    print(most_common_space)\n",
    "\n",
    "    len_content = len(items) / 5.5\n",
    "\n",
    "    for i,k in enumerate(items):\n",
    "        try:\n",
    "            if abs(items[i][2][0][0][1] - items[i -1][2][0][0][1]) >= most_common_space -len_content:\n",
    "                new_content.append([])\n",
    "                new_content.append(items[i][2])\n",
    "            else:\n",
    "                new_content.append(items[i][2])\n",
    "        except:\n",
    "            new_content.append(items[i][2])\n",
    "\n",
    "\n",
    "    # group the contents based on horizontal space. grouping the contents anywhere we find '[]'\n",
    "    new_content = [list(l) for i, l in groupby(new_content, bool) if i]\n",
    "\n",
    "    # join list that the length is greater than one. so that it is easier to loop through\n",
    "    for i in range(len(new_content)):\n",
    "        if len(new_content[i]) > 1:\n",
    "            new_content[i] = sum(new_content[i], [])\n",
    "            new_content[i] = [new_content[i]]\n",
    "        else:\n",
    "            new_content[i] = new_content[i]\n",
    "\n",
    "\n",
    "    # find common width of white space on the document\n",
    "    def find_common_diff(content):\n",
    "        diffs = []\n",
    "        for i,j in enumerate(new_content):\n",
    "            for u,t in enumerate(new_content[i][0]):\n",
    "                try:\n",
    "                    difference = abs(new_content[i][0][u][0][2] - new_content[i][0][u-1][0][0])\n",
    "                    diffs.append(difference)\n",
    "                except:\n",
    "                    ...\n",
    "        common_diffs = abs(statistics.median(diffs))\n",
    "        return common_diffs\n",
    "\n",
    "    # find common width of white space on a line\n",
    "    def find_common_diff_in_line(content):\n",
    "        diffs = []\n",
    "        for i,j in enumerate(new_content):\n",
    "            temp_diffs = []\n",
    "            for u,t in enumerate(new_content[i][0]):\n",
    "                try:\n",
    "                    difference = abs(new_content[i][0][u][0][0] - new_content[i][0][u-1][0][2])\n",
    "                    temp_diffs.append(difference)\n",
    "                except:\n",
    "                    ...\n",
    "            diffs.append(temp_diffs)\n",
    "        return diffs\n",
    "\n",
    "\n",
    "    def check_for_max_width(new_content):\n",
    "        \"\"\"Find the texts with the hightest width. The purpose of this that if a text if very long that it \n",
    "        takes up almost half line of the document then we will just use the most common width in the line instead of the document\n",
    "        \"\"\"\n",
    "        widths = []\n",
    "        for i,j in enumerate(new_content):\n",
    "            temp_diffs = []\n",
    "            for u,t in enumerate(new_content[i][0]):\n",
    "                try:\n",
    "                    text_width = abs(new_content[i][0][u][0][0] - new_content[i][0][u][0][2])\n",
    "                    temp_diffs.append(text_width)\n",
    "                except:\n",
    "                    ...\n",
    "            widths.append(temp_diffs)\n",
    "        max_width = max(widths)\n",
    "        return widths\n",
    "\n",
    "    # split line content based on vertical spacing\n",
    "    contents = []\n",
    "    max_text_width = 600\n",
    "    most_common_diffs = find_common_diff(new_content)\n",
    "\n",
    "    for i,j in enumerate(new_content):\n",
    "        \"\"\"This snippet groups the document based on vertival spacing\"\"\"\n",
    "        temp_content = []\n",
    "        most_common_diffs_in_a_line = abs(statistics.median(find_common_diff_in_line(new_content)[i]))\n",
    "        text_width = check_for_max_width(new_content)[i] # checking for max width of texts\n",
    "        max_width = max(text_width)\n",
    "        for u,t in enumerate(new_content[i][0]):\n",
    "            try:\n",
    "                difference = abs(new_content[i][0][u][0][0] - new_content[i][0][u-1][0][2])\n",
    "                if most_common_diffs >= most_common_diffs_in_a_line and max_width < max_text_width:\n",
    "                    if difference >= most_common_diffs_in_a_line+100: # getting the min width of white space in that line\n",
    "                        temp_content.append([])\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "\n",
    "                    else:\n",
    "                        temp_content.append(new_content[i][0][u]) \n",
    "                elif most_common_diffs >= most_common_diffs_in_a_line and max_width > max_text_width:\n",
    "\n",
    "                    if difference > most_common_diffs_in_a_line-15: # getting the min width of white space in that line\n",
    "                        temp_content.append([])\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "\n",
    "                    else:\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "                else:\n",
    "    #                 This bias (20) should increase or decrease depend on document\n",
    "                    if difference > most_common_diffs+20: # getting the most common width of white space in the doc\n",
    "                        temp_content.append([])\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "\n",
    "                    else:\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "            except:\n",
    "                ...\n",
    "        # grouping the contents that are family :). grounping the contents anywhere we see '[]'\n",
    "        new_temp_content = [list(l) for i, l in groupby(temp_content, bool) if i]\n",
    "        contents.append(new_temp_content)    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    # Extract the first 3 contents that the starting position is less than 80 and the bottom position is less than 300 \n",
    "    # This is specific to what is need to extract at the moment for the Japanese document. so we are not parsing the whole document\n",
    "    max_bottom_position = 300\n",
    "    max_start_pos = 80\n",
    "\n",
    "    new_contents = []\n",
    "    for item in range(len(contents)):\n",
    "        context_in_line = contents[item][0]\n",
    "        start_position = contents[item][0][0][0][0]\n",
    "        bottom_position = contents[item][0][0][0][1]\n",
    "        if start_position < max_start_pos and bottom_position < max_bottom_position:\n",
    "            new_contents.append(context_in_line)\n",
    "        else:\n",
    "            ...\n",
    "\n",
    "\n",
    "    # get the bound for croping out the detected text\n",
    "    bounds = []\n",
    "    for i in range(len(new_contents)):\n",
    "        line_bound = []\n",
    "        for u in range(len(new_contents[i]) - len(new_contents[i])+1):\n",
    "            first_top = new_contents[i][u][0][3][0]\n",
    "            last_bottom = new_contents[i][u-1][0][3][2]\n",
    "            bound = [first_top, last_bottom]\n",
    "            line_bound.append(bound)\n",
    "        bounds.append(line_bound)\n",
    "\n",
    "    # Get crop hint\n",
    "    crop_hints_params = vision.CropHintsParams(aspect_ratios=[1.77])\n",
    "    def get_crop_hint(crop_hints):\n",
    "        \"\"\"Detect crop hints on a single image and return the first result.\"\"\"\n",
    "        with io.open(crop_hints, 'rb') as image_file1:\n",
    "            content = image_file1.read()\n",
    "\n",
    "        # content = crop_hints\n",
    "        image = vision.Image(content=content)\n",
    "\n",
    "        image_context = vision.ImageContext(crop_hints_params=crop_hints_params)\n",
    "\n",
    "        response = client.crop_hints(image=image, image_context=image_context)\n",
    "        hints = response.crop_hints_annotation.crop_hints\n",
    "\n",
    "        # Get bounds for the first crop hint using an aspect ratio of 1.77.\n",
    "        vertices = hints[0].bounding_poly.vertices\n",
    "\n",
    "        return vertices\n",
    "\n",
    "    def crop_Text_hint(image_file, TextAnnotations):\n",
    "        \"\"\"Crop the image using the hints in the vector list.\"\"\"\n",
    "        vects = get_crop_hint(image_file)\n",
    "        TextAnnotations = TextAnnotations\n",
    "        try:\n",
    "            images = []\n",
    "            for i in range(len(TextAnnotations)):\n",
    "                bound_1 = TextAnnotations[i][0][0]\n",
    "                bound_2 = TextAnnotations[i][0][1]\n",
    "                bound_1 = eval(bound_1)\n",
    "                bound_2 = eval(bound_2)\n",
    "\n",
    "                im = Image.open(image_file)\n",
    "\n",
    "                im2 = im.crop([bound_1[0], bound_1[1],\n",
    "                              bound_2[0] - 1, bound_2[1] - 1])\n",
    "    #             unique_id = uuid.uuid4().hex\n",
    "    #             output = f'output_{unique_id}.jpg'\n",
    "    #             im2.save(output, 'JPEG')\n",
    "                images.append(im2)\n",
    "            return images\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"No Image Detected\")\n",
    "\n",
    "    croped_out = crop_Text_hint(os.path.join(FOLDER_PATH, image), bounds)\n",
    "    # face\n",
    "\n",
    "    max_diff = 10\n",
    "    main_contents = []\n",
    "    for i,j in enumerate(new_contents):\n",
    "        \"\"\" Grouping the contents based on vertical spacing . This is where we get the get the keys and values\"\"\"\n",
    "        temp_content = []\n",
    "        for u,t in enumerate(new_contents[i]):\n",
    "            try:\n",
    "                print(new_contents[i][u][0][0])\n",
    "                difference = abs(new_contents[i][u][0][0] - new_contents[i][u-1][0][2])\n",
    "                print(difference)\n",
    "                if difference > max_diff: # getting the most common width of white space in the doc\n",
    "                    temp_content.append([])\n",
    "                    temp_content.append(new_contents[i][u])\n",
    "                else:\n",
    "                    temp_content.append(new_contents[i][u])\n",
    "            except:\n",
    "                temp_content.append(new_contents[i][u])\n",
    "        new_temp_content = [list(l) for i, l in groupby(temp_content, bool) if i]\n",
    "        main_contents.append(new_temp_content)\n",
    "    # print(main_contents)\n",
    "\n",
    "    jap_contents = []\n",
    "    images_of_extracted_values = []\n",
    "    max_starting_pos = 100\n",
    "\n",
    "    for i in range(len(main_contents)):\n",
    "        \"\"\"Convert the lists we grouped above into keys and values\"\"\"\n",
    "        keys = ''\n",
    "        values = ''\n",
    "        for u in range(len(main_contents[i])):\n",
    "            left_bbox = main_contents[i][u][0][0][0]\n",
    "            if left_bbox <=max_starting_pos:\n",
    "                try:\n",
    "                    for j in range(len(main_contents[i][u])):\n",
    "                        text = main_contents[i][u][j][1]\n",
    "                        keys += ' '+text\n",
    "                except:\n",
    "                    ...\n",
    "            else:\n",
    "                try:\n",
    "                    for j in range(len(main_contents[i][u])):\n",
    "                        text = main_contents[i][u][j][1]\n",
    "                        if abs(main_contents[i][u][j][0][0] - main_contents[i][u-1][j][0][0]) <= 41:\n",
    "                            values += ''+text\n",
    "                        else:\n",
    "                            values += ' '+text\n",
    "                except:\n",
    "                    ...\n",
    "        # Translate the keys\n",
    "        text_translate = translate_client.translate(keys, target_language='en')['translatedText']\n",
    "        keys = keys + \" / \" +  text_translate\n",
    "        jap_contents.append({keys:values}) # Keys and values\n",
    "        ith_image = croped_out[i]\n",
    "        try: # convert the image to bytes to enable html display\n",
    "#             buf = io.BytesIO()\n",
    "#             ith_image.save(buf, format='PNG')\n",
    "#             ith_image = buf.getvalue()\n",
    "            images_of_extracted_values.append(ith_image)\n",
    "        except:\n",
    "            images_of_extracted_values.append(croped_out[i])\n",
    "\n",
    "    return jap_contents, images_of_extracted_values # return the contents and images of the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find the most common space\n",
    "def af_parser(image):\n",
    "    \"\"\"This functionality is built to parse the South African documents\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Open and Read contents on the documents\n",
    "    with io.open(image, 'rb') as image_file1:\n",
    "            content = image_file1.read()\n",
    "    content_image = vision.Image(content=content) # Reading the Image Content\n",
    "    rc1_response = client.text_detection(image=content_image) # Text Detection \n",
    "    rc1_texts = rc1_response.text_annotations # Text Response\n",
    "\n",
    "    # face detection\n",
    "    response_face = client.face_detection(image=content_image)\n",
    "    faceAnnotations = response_face.face_annotations\n",
    "    \n",
    "    \n",
    "    # rearrange the Response using the bbox values\n",
    "    items = []\n",
    "    lines = {}\n",
    "\n",
    "    for text in rc1_response.text_annotations[1:]:\n",
    "        left_x_axis = text.bounding_poly.vertices[0].x # top left\n",
    "        left_y_axis = text.bounding_poly.vertices[0].y # top left\n",
    "        top_x_axis = text.bounding_poly.vertices[1].x # top\n",
    "        top_y_axis = text.bounding_poly.vertices[1].y # top\n",
    "        right_x_axis = text.bounding_poly.vertices[2].x # right\n",
    "        right_y_axis = text.bounding_poly.vertices[2].y # right\n",
    "        bottom_x_axis = text.bounding_poly.vertices[3].x # bottom\n",
    "        bottom_y_axis = text.bounding_poly.vertices[3].y # bottom\n",
    "        \n",
    "        # Arranging the bounding_polys\n",
    "        if left_y_axis not in lines:\n",
    "            lines[left_y_axis] = [(left_y_axis, bottom_y_axis), []]\n",
    "        for s_top_y_axis, s_item in lines.items():\n",
    "            if left_y_axis < s_item[0][1]:\n",
    "                face_vertices = (['({0},{1})'.format(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices])\n",
    "                                           #     Left          # Bottom      # top Right        # vertices.        # Text            incase you still want to rearrange them in the future\n",
    "                lines[s_top_y_axis][1].append(([left_x_axis, bottom_y_axis, top_x_axis, (face_vertices)], text.description))\n",
    "                break\n",
    "    for _, item in lines.items():\n",
    "        if item[1]:\n",
    "            words = sorted(item[1], key=lambda t: t[0])\n",
    "            items.append((item[0], ' '.join([word for _, word in words]), words))\n",
    "            \n",
    "    def find_common_space(items):\n",
    "        \"\"\"Find common line spaces in the document\"\"\"\n",
    "        spaces = []\n",
    "        for i,k in enumerate(items):\n",
    "            try:\n",
    "                calculated_space = items[i][2][0][0][1] - items[i -1][2][0][0][1]\n",
    "                spaces.append(calculated_space)\n",
    "            except:\n",
    "                ...\n",
    "\n",
    "        common_space = abs(statistics.median(spaces))\n",
    "\n",
    "        return common_space\n",
    "\n",
    "    # Split the content based on horizontal space\n",
    "\n",
    "    new_content = []\n",
    "\n",
    "    most_common_space = find_common_space(items)\n",
    "\n",
    "    len_content = len(items) / 5.5\n",
    "    start_pos = 300\n",
    "\n",
    "    for i,k in enumerate(items):\n",
    "        prev_item = items[i-1][2][0]\n",
    "        left_bbox = items[i][2][0][0][0]\n",
    "        \n",
    "        prev_left_bbox = items[i-1][2][0][0][0]\n",
    "        curr_first_letter = items[i][2][0][1][0]\n",
    "        prev_first_letter = items[i-1][2][0][1][0]\n",
    "        #Check if a line has keys and values by checking the lenght\n",
    "        Curr_item_last_left_bbox = []\n",
    "        for u in range(len(items[i])):\n",
    "            try:\n",
    "                if items[i][2][u][0][0] < 790:\n",
    "                    Curr_item_last_left_bbox.append(items[i][2][u][0][0])\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "#             if abs(items[i][2][0][0][1] - items[i -1][2][0][0][1]) >= most_common_space -len_content and not (prev_first_letter.isupper() and curr_first_letter.islower() and len(items[i][2]) == 1) and not (left_bbox > start_pos and not len(prev_item) == 1):\n",
    "            if abs(items[i][2][0][0][1] - items[i -1][2][0][0][1]) >= most_common_space -len_content and not (prev_first_letter.isupper() and curr_first_letter.islower() and len(Curr_item_last_left_bbox) == 1) and not (left_bbox > start_pos and not len(prev_item) == 1):\n",
    "                new_content.append([])\n",
    "                new_content.append(items[i][2])\n",
    "            else:\n",
    "                new_content.append(items[i][2])\n",
    "        except:\n",
    "            new_content.append(items[i][2])\n",
    "\n",
    "\n",
    "    # group the contents based on horizontal space. grouping the contents anywhere we find '[]'\n",
    "    new_content = [list(l) for i, l in groupby(new_content, bool) if i]\n",
    "\n",
    "    # join list that the length is greater than one\n",
    "    for i in range(len(new_content)):\n",
    "        if len(new_content[i]) > 1:\n",
    "            new_content[i] = sum(new_content[i], [])\n",
    "            new_content[i] = [new_content[i]]\n",
    "        else:\n",
    "            new_content[i] = new_content[i]\n",
    "\n",
    "    # find common width of white space on the document\n",
    "    def find_common_diff(content):\n",
    "        diffs = []\n",
    "        for i,j in enumerate(new_content):\n",
    "            for u,t in enumerate(new_content[i][0]):\n",
    "                try:\n",
    "                    difference = abs(new_content[i][0][u][0][2] - new_content[i][0][u-1][0][0])\n",
    "                    diffs.append(difference)\n",
    "                except:\n",
    "                    ...\n",
    "        common_diffs = abs(statistics.median(diffs))\n",
    "        return common_diffs\n",
    "\n",
    "    # find common width of white space on a line\n",
    "    def find_common_diff_in_line(content):\n",
    "        diffs = []\n",
    "        for i,j in enumerate(new_content):\n",
    "            temp_diffs = []\n",
    "            for u,t in enumerate(new_content[i][0]):\n",
    "                try:\n",
    "                    difference = abs(new_content[i][0][u][0][0] - new_content[i][0][u-1][0][2])\n",
    "                    temp_diffs.append(difference)\n",
    "                except:\n",
    "                    ...\n",
    "            diffs.append(temp_diffs)\n",
    "        return diffs\n",
    "\n",
    "    def check_for_max_width(new_content):\n",
    "        '''Check for max with of a text in a line'''\n",
    "        \"\"\"Find the texts with the hightest width. The purpose of this that if a text if very long that it \n",
    "        takes up almost half line of the document then we will just use the most common width in the line instead of the document\n",
    "        \"\"\"\n",
    "        widths = []\n",
    "        for i,j in enumerate(new_content):\n",
    "            temp_diffs = []\n",
    "            for u,t in enumerate(new_content[i][0]):\n",
    "                try:\n",
    "                    text_width = abs(new_content[i][0][u][0][0] - new_content[i][0][u][0][2])\n",
    "                    temp_diffs.append(text_width)\n",
    "                except:\n",
    "                    ...\n",
    "            widths.append(temp_diffs)\n",
    "        max_width = max(widths)\n",
    "        return widths\n",
    "\n",
    "    # split line content based on vertical spacing\n",
    "    contents = []\n",
    "    max_text_width = 600\n",
    "    most_common_diffs = find_common_diff(new_content)\n",
    "\n",
    "    for i,j in enumerate(new_content):\n",
    "        \"\"\"This snippet groups the document based on vertival spacing. First move to getting the Keys and values\"\"\"\n",
    "        temp_content = []\n",
    "        most_common_diffs_in_a_line = abs(statistics.median(find_common_diff_in_line(new_content)[i]))\n",
    "        text_width = check_for_max_width(new_content)[i]\n",
    "        max_width = max(text_width)\n",
    "        for u,t in enumerate(new_content[i][0]):\n",
    "            try:\n",
    "                difference = abs(new_content[i][0][u][0][0] - new_content[i][0][u-1][0][2])\n",
    "                if most_common_diffs >= most_common_diffs_in_a_line and max_width < max_text_width:\n",
    "                    if difference >= most_common_diffs_in_a_line+20: # getting the min width of white space in that line\n",
    "                        temp_content.append([])\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "\n",
    "                    else:\n",
    "                        temp_content.append(new_content[i][0][u]) \n",
    "                elif most_common_diffs >= most_common_diffs_in_a_line and max_width > max_text_width:\n",
    "                    if difference > most_common_diffs_in_a_line-15: # getting the min width of white space in that line\n",
    "                        temp_content.append([])\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "\n",
    "                    else:\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "                else:\n",
    "                    if difference > most_common_diffs-65: # getting the most common width of white space in the doc\n",
    "                        temp_content.append([])\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "\n",
    "                    else:\n",
    "                        temp_content.append(new_content[i][0][u])\n",
    "            except:\n",
    "                ...\n",
    "        # Grouping the contents anywhere we find '[]'\n",
    "        new_temp_content = [list(l) for i, l in groupby(temp_content, bool) if i]\n",
    "        contents.append(new_temp_content)    \n",
    "\n",
    "    def extract_keys_and_values(contents):\n",
    "        \"\"\" This functionality extracts they keys and values as in the document structure\"\"\"\n",
    "        def check_for_non_english(new_content):\n",
    "            \"\"\"this function was built to Counts the number of non-english and english texts in a line. but because of the \n",
    "            time complexity the algorithm was removed while I still keep the function name. incase if you're wondering\n",
    "            So what this function does is to counts sentences/words that the starting position is less than 780 and the give the line a score\"\"\"\n",
    "            max_pos = 780 # this is the max starting position that an english word does exceed\n",
    "            translate_client = translate.Client()\n",
    "            target = 'en'\n",
    "            detected_words = []\n",
    "            for i,j in enumerate(new_content):\n",
    "                temp_words = []\n",
    "                for u,t in enumerate(new_content[i]):\n",
    "                    counts = {'en':0, 'af':0} # score counts. \"en\" is english and \"af\" is any other language\n",
    "                    left_bbox = contents[i][u][0][0][0]\n",
    "                    for s,r in enumerate(new_content[i][u]):\n",
    "                        try:\n",
    "                            text = new_content[i][u][s][1]\n",
    "\n",
    "                            if left_bbox < max_pos:\n",
    "                                counts['en'] += 1\n",
    "                            else:\n",
    "                                counts['af'] += 1\n",
    "                        except:\n",
    "                            ...\n",
    "                    temp_words.append(counts)\n",
    "                detected_words.append(temp_words)\n",
    "            return detected_words\n",
    "\n",
    "        word_detection = check_for_non_english(contents)\n",
    "\n",
    "        new_contents = []\n",
    "        max_position = 1200\n",
    "        list_of_special_keywords = ['RC1', 'RNC', 'RTS', 'NRW'] # special key words to add to the extracted values\n",
    "\n",
    "        for i,j in enumerate(contents): # \n",
    "            temp_content = []\n",
    "            word_detected = word_detection[i]\n",
    "            content = contents[i]\n",
    "            for u,t in enumerate(contents[i]):\n",
    "                left_bbox = contents[i][u][0][0][0]\n",
    "                if word_detected[u]['en'] > word_detected[u]['af'] and left_bbox < max_position or contents[i][u][0][1] in list_of_special_keywords:\n",
    "                    temp_content.append(content[u])\n",
    "            new_contents.append(temp_content)\n",
    "\n",
    "        # get the left bbox of the keys\n",
    "        new_contents = [x for x in new_contents if x != []]\n",
    "        return new_contents\n",
    "\n",
    "    def crop_extracted_info(new_contents):\n",
    "        # get the bound for croping out the detected text\n",
    "        bounds = []\n",
    "        for i in range(len(new_contents)):\n",
    "            line_bound = []\n",
    "            if len(new_contents[i]) > 1:\n",
    "                for u in range(len(new_contents[i])):\n",
    "                    left_max = ()\n",
    "                    top_max = ()\n",
    "                    right_max = ()\n",
    "                    bottom_max = ()\n",
    "                    try:\n",
    "                        top = []\n",
    "                        bottom = []\n",
    "                        right = []\n",
    "                        left = []\n",
    "                        right_elements_list = []\n",
    "                        left_elements_list = []\n",
    "                        # Separate the bbox accordingly \n",
    "                        if new_contents[i][u][0][0][0] > 400:\n",
    "                            right_elements_list.append(new_contents[i][u])\n",
    "                        else:\n",
    "                            left_elements_list.append(new_contents[i][u])\n",
    "                        for o in range(len(right_elements_list)):\n",
    "                            if right_elements_list[o] != []: # get the bbox accordingly for croping the extracted text\n",
    "                                for e in range(len(right_elements_list[o])):\n",
    "                                    left.append(eval(right_elements_list[o][e][0][3][0]))\n",
    "                                    top.append(eval(right_elements_list[o][e][0][3][1]))\n",
    "                                    right.append(eval(right_elements_list[o][e-1][0][3][2])) # the last items from the right\n",
    "                                    bottom.append(eval(right_elements_list[o][e][0][3][3]))\n",
    "                        for o in range(len(left_elements_list)):\n",
    "                            if left_elements_list[o] != []: # get the bbox accordingly for croping the extracted text\n",
    "                                for e in range(len(left_elements_list[o])):\n",
    "                                    left.append(eval(left_elements_list[o][e][0][3][0]))\n",
    "                                    top.append(eval(left_elements_list[o][e][0][3][1]))\n",
    "                                    right.append(eval(left_elements_list[o][e][0][3][2]))\n",
    "                                    bottom.append(eval(left_elements_list[o][e][0][3][3]))\n",
    "\n",
    "                        # get the max and min bounds for top, left ... etc\n",
    "\n",
    "                        left_max = sorted(left,key=lambda x: x[0], reverse=False)[0]\n",
    "                        top_max = sorted(top,key=lambda x: x[0], reverse=True)[0]\n",
    "                        right_max = sorted(right,key=lambda x: x[0], reverse=True)[0]\n",
    "                        bottom_max = sorted(bottom,key=lambda x: x[0], reverse=True)[0]\n",
    "\n",
    "                    except:\n",
    "                        ...\n",
    "\n",
    "                    bound = [left_max, top_max, right_max, bottom_max]\n",
    "                    line_bound.append(bound)\n",
    "                bounds.append(line_bound)\n",
    "            else:\n",
    "                for u in range(len(new_contents[i])):\n",
    "                    first_top = []\n",
    "                    last_bottom = []\n",
    "                    try:\n",
    "                        first_top = new_contents[i][u][0][0][3][0]\n",
    "                        last_bottom = new_contents[i][u-1][-1][0][3][2]\n",
    "                    except:\n",
    "                        ...\n",
    "\n",
    "                    bound = [first_top, last_bottom]\n",
    "                    line_bound.append(bound)\n",
    "                bounds.append(line_bound)\n",
    "\n",
    "        # Get crop hint\n",
    "        crop_hints_params = vision.CropHintsParams(aspect_ratios=[1.77])\n",
    "        def get_crop_hint(crop_hints):\n",
    "            \"\"\"Detect crop hints on a single image and return the first result.\"\"\"\n",
    "            with io.open(crop_hints, 'rb') as image_file1:\n",
    "                content = image_file1.read()\n",
    "\n",
    "            # content = crop_hints\n",
    "            image = vision.Image(content=content)\n",
    "            image_context = vision.ImageContext(crop_hints_params=crop_hints_params)\n",
    "\n",
    "            response = client.crop_hints(image=image, image_context=image_context)\n",
    "            hints = response.crop_hints_annotation.crop_hints\n",
    "\n",
    "            # Get bounds for the first crop hint using an aspect ratio of 1.77.\n",
    "            vertices = hints[0].bounding_poly.vertices\n",
    "\n",
    "            return vertices\n",
    "\n",
    "        def crop_Text_hint(image_file, TextAnnotations):\n",
    "            \"\"\"Crop the image using the hints in the vector list.\"\"\"\n",
    "            vects = get_crop_hint(image_file)\n",
    "            TextAnnotations = TextAnnotations\n",
    "            try:\n",
    "                images = []\n",
    "                for i in range(len(TextAnnotations)):\n",
    "                    try:\n",
    "                        sum_bounds = []\n",
    "                        for c in range(len(TextAnnotations[i])):\n",
    "                            sum_bounds.append(TextAnnotations[i][c])\n",
    "                        sum_bounds = sum(sum_bounds, [])\n",
    "                        bound_1 = TextAnnotations[i][0][0]\n",
    "                        bound_2 = TextAnnotations[i][0][1]\n",
    "                        bound_3 = sorted(sum_bounds,key=lambda x: x[0], reverse=True)[0]\n",
    "                        bound_4 = TextAnnotations[i][-1][3]\n",
    "                        bound_1 = bound_1 # left\n",
    "                        bound_2 = bound_2 # top\n",
    "                        bound_3 = bound_3 # right\n",
    "                        bound_4 = bound_4 # bottom\n",
    "                        im = Image.open(image_file)\n",
    "\n",
    "                        # check which of the values are higher\n",
    "                        if bound_3[0] > bound_3[1]:\n",
    "\n",
    "                            im2 = im.crop([bound_1[0]-1, bound_2[1]-7,\n",
    "                                          bound_3[0]+5, bound_4[1] + 5]) # added some padding\n",
    "                            images.append(im2)\n",
    "                        else:\n",
    "                            im2 = im.crop([bound_1[0]-1, bound_2[1]-10,\n",
    "                                      bound_3[0]+5, bound_4[1]+5]) # added some padding\n",
    "                            images.append(im2)\n",
    "                    except:\n",
    "                        bound_1 = TextAnnotations[i][0][0]\n",
    "                        bound_2 = TextAnnotations[i][0][1]\n",
    "                        # sum the list if the len is greater than 1\n",
    "                        try:\n",
    "                            bound_1 = sum(bound_1[0], [])\n",
    "                            bound_2 = sum(bound_2[0], [])\n",
    "                        except:\n",
    "                            ...\n",
    "                        try:\n",
    "                            bound_1 = eval(bound_1)\n",
    "                            bound_2 = eval(bound_2)\n",
    "                        except:\n",
    "                            ...\n",
    "\n",
    "                        im = Image.open(image_file)\n",
    "\n",
    "                        im2 = im.crop([bound_1[0]-1, bound_1[1]-7,\n",
    "                                      bound_2[0] + 5, bound_2[1] + 5]) # added some padding\n",
    "                        images.append(im2)\n",
    "                return images\n",
    "            except Exception as e:\n",
    "                exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "                # print(exc_type, fname, exc_tb.tb_lineno)\n",
    "                # print(e)\n",
    "                # print(\"No Image Detected\")\n",
    "\n",
    "        croped_out = crop_Text_hint(image, bounds)\n",
    "\n",
    "        return croped_out\n",
    "\n",
    "    def get_values(new_contents):\n",
    "        \"\"\"This functionality get the keys and values in a key pair or dictionary\"\"\"\n",
    "        left_bbox_lists = []\n",
    "        for i in range(len(new_contents)):\n",
    "            try:\n",
    "                left_bbox = new_contents[i][0][0][0][0]\n",
    "                left_bbox_lists.append(left_bbox)\n",
    "            except:\n",
    "                left_bbox = 0\n",
    "                left_bbox_lists.append(left_bbox)\n",
    "\n",
    "        max_left_bbox = max(left_bbox_lists)\n",
    "\n",
    "        # getting the keys and values \n",
    "        rc1_contents = []\n",
    "        max_starting_pos = 250\n",
    "\n",
    "        for i in range(len(new_contents)):\n",
    "            keys = ''\n",
    "            values = ''\n",
    "            for u in range(len(new_contents[i])):\n",
    "                left_bbox = new_contents[i][u][0][0][0]\n",
    "                if left_bbox <= max_left_bbox and left_bbox <=max_starting_pos:\n",
    "                    try:\n",
    "                        for j in range(len(new_contents[i][u])):\n",
    "                            text = new_contents[i][u][j][1]\n",
    "                            keys += ' '+text\n",
    "                    except:\n",
    "                        ...\n",
    "                else:\n",
    "                    try:\n",
    "                        for j in range(len(new_contents[i][u])):\n",
    "                            text = new_contents[i][u][j][1]\n",
    "                            values += ' '+text\n",
    "                    except:\n",
    "                        ...\n",
    "\n",
    "            rc1_contents.append({keys:values})\n",
    "        return rc1_contents\n",
    "\n",
    "#     contents = arrange_the_texts(rc1_response)\n",
    "\n",
    "    contents = extract_keys_and_values(contents)\n",
    "\n",
    "    # crop out the values to be extracted\n",
    "    croped_out = crop_extracted_info(contents)\n",
    "\n",
    "    # extract the values\n",
    "    contents = get_values(contents)\n",
    "    # keys needed to be pulled out from the document\n",
    "    keys_to_pull_out_RNC = ['Registering authority', 'Traffic register number', 'Name', 'Postal address', 'Street address', 'Address where notices must be served', 'Control number', 'Issue number', 'Date of issue']\n",
    "    keys_not_to_pull_out_RC1 = [ \"4024\", \"at Registering which registered authority\", \"RET(7)(2005/02)\", \"Republic of South Africa\" ]\n",
    "    keys_not_to_pull_out_NRW = [\"NRW(2)(2003/10)\", \"NOTICE\", \"PARTICULARS (National Road Traffic OF Act, VEHICLE\"]\n",
    "\n",
    "    # change the keys to upper case\n",
    "    keys_to_pull_out_RNC = [i.upper().strip() for i in keys_to_pull_out_RNC]\n",
    "    keys_not_to_pull_out_RC1 = [i.upper().strip() for i in keys_not_to_pull_out_RC1]\n",
    "    keys_not_to_pull_out_NRW = [i.upper().strip() for i in keys_not_to_pull_out_NRW]\n",
    "\n",
    "    extracted_values = []\n",
    "    images_of_extracted_values = []\n",
    "\n",
    "    # check if the special keys are in the document, if so pull the right keys\n",
    "    for e,f in contents[0].items():\n",
    "        if 'RNC' in f:\n",
    "            for i in range(len(contents)):\n",
    "                for key, value in contents[i].items():\n",
    "                    key = ' '.join(key.split())\n",
    "                    if key.upper() in keys_to_pull_out_RNC:\n",
    "                        extracted_values.append(contents[i])\n",
    "                        ith_image = croped_out[i]\n",
    "                        try: # convert the image to bytes to enable html display\n",
    "    #                             buf = io.BytesIO()\n",
    "    #                             ith_image.save(buf, format='PNG')\n",
    "    #                             ith_image = buf.getvalue()\n",
    "                            images_of_extracted_values.append(ith_image)\n",
    "                        except:\n",
    "                            images_of_extracted_values.append(croped_out[i]) # this is from the images croped out\n",
    "        elif 'RC1' in f:\n",
    "            for i in range(len(contents)):\n",
    "                for key, value in contents[i].items():\n",
    "                    key = ' '.join(key.split())\n",
    "                    if key.upper() in keys_not_to_pull_out_RC1:\n",
    "                        ...\n",
    "                    else:\n",
    "                        if key != '':\n",
    "                            extracted_values.append(contents[i])\n",
    "                            ith_image = croped_out[i]\n",
    "                            try: # convert the image to bytes to enable html display\n",
    "    #                                 buf = io.BytesIO()\n",
    "    #                                 ith_image.save(buf, format='PNG')\n",
    "    #                                 ith_image = buf.getvalue()\n",
    "                                images_of_extracted_values.append(ith_image)\n",
    "                            except:\n",
    "                                images_of_extracted_values.append(croped_out[i]) # this is from the images croped out\n",
    "        elif 'NRW' in f:\n",
    "            for i in range(len(contents)):\n",
    "                for key, value in contents[i].items():\n",
    "                    key = ' '.join(key.split())\n",
    "                    if key.upper() in keys_not_to_pull_out_NRW:\n",
    "                        ...\n",
    "                    else:\n",
    "                        if key != '':\n",
    "                            extracted_values.append(contents[i])\n",
    "                            ith_image = croped_out[i]\n",
    "                            try: # convert the image to bytes to enable html display\n",
    "    #                                 buf = io.BytesIO()\n",
    "    #                                 ith_image.save(buf, format='PNG')\n",
    "    #                                 ith_image = buf.getvalue()\n",
    "                                images_of_extracted_values.append(ith_image)\n",
    "                            except:\n",
    "                                images_of_extracted_values.append(croped_out[i]) # this is from the images croped out\n",
    "        else:\n",
    "            extracted_values.append({'Oops!':'document has a different structure'})\n",
    "    print(extracted_values)\n",
    "    return extracted_values, images_of_extracted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(image):\n",
    "    \"\"\"This functionality does a check to see if the loaded document is the japanese document or the south african. And then\n",
    "    calls the apropriate algorithm\"\"\"\n",
    "    is_japanese_parser = False\n",
    "    \n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Open and Read contents on the documents\n",
    "    with io.open(image, 'rb') as image_file1:\n",
    "            content = image_file1.read()\n",
    "    content_image = vision.Image(content=content) # Reading the Image Content\n",
    "    rc1_response = client.document_text_detection(image=content_image) # Text Detection \n",
    "    rc1_texts = rc1_response.text_annotations # Text Response\n",
    "#     print(rc1_texts)\n",
    "\n",
    "    # face detection\n",
    "    response_face = client.face_detection(image=content_image)\n",
    "    faceAnnotations = response_face.face_annotations\n",
    "    \n",
    "    \n",
    "    # rearrange the Response using the bbox values\n",
    "    items = []\n",
    "    lines = {}\n",
    "\n",
    "    for text in rc1_response.text_annotations[1:]:\n",
    "        left_x_axis = text.bounding_poly.vertices[0].x # top left\n",
    "        left_y_axis = text.bounding_poly.vertices[0].y # top left\n",
    "        top_x_axis = text.bounding_poly.vertices[1].x # top\n",
    "        top_y_axis = text.bounding_poly.vertices[1].y # top\n",
    "        right_x_axis = text.bounding_poly.vertices[2].x # right\n",
    "        right_y_axis = text.bounding_poly.vertices[2].y # right\n",
    "        bottom_x_axis = text.bounding_poly.vertices[3].x # bottom\n",
    "        bottom_y_axis = text.bounding_poly.vertices[3].y # bottom\n",
    "\n",
    "        if left_y_axis not in lines:\n",
    "            lines[left_y_axis] = [(left_y_axis, bottom_y_axis), []]\n",
    "        for s_top_y_axis, s_item in lines.items():\n",
    "            if left_y_axis < s_item[0][1]:\n",
    "                face_vertices = (['({0},{1})'.format(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices])\n",
    "                lines[s_top_y_axis][1].append(([left_x_axis, bottom_y_axis, top_x_axis, (face_vertices)], text.description))\n",
    "                break\n",
    "    for _, item in lines.items():\n",
    "        if item[1]:\n",
    "            words = sorted(item[1], key=lambda t: t[0])\n",
    "            items.append((item[0], ' '.join([word for _, word in words]), words))\n",
    "\n",
    "    # Check if the document is the japanese document\n",
    "    if items[0][2][0][1][0] == 'ç•ª':\n",
    "        is_japanese_parser = True\n",
    "            \n",
    "        \n",
    "    if is_japanese_parser:\n",
    "        ex_vals, img_of_ex_vals = jap_parser(image) # Japanese document Algorithm\n",
    "        return ex_vals, img_of_ex_vals\n",
    "    else:\n",
    "        ex_vals, img_of_ex_vals = af_parser(image) # South African document Algorithm\n",
    "        return ex_vals, img_of_ex_vals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "71\n",
      "235\n",
      "217\n",
      "45\n",
      "70\n",
      "515\n",
      "172\n",
      "7\n",
      "281\n",
      "20\n",
      "78\n",
      "424\n",
      "189\n",
      "48\n",
      "223\n",
      "20\n",
      "261\n",
      "25\n",
      "387\n",
      "120\n",
      "422\n",
      "20\n",
      "455\n",
      "20\n",
      "495\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "ex_vals, img_of_ex_vals = parser(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{' ç•ªå· / number': ' 00858'},\n",
       " {' æ•´ç† ç•ªå· / Reference number': ' 3911024991745631'},\n",
       " {' ç¦å²¡ / Fukuoka': ' 499 4563'}]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ç•ªå· / number': ' 00858'}"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=234x30 at 0x1A1FDC9C400>"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_of_ex_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
